{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<SparkContext master=local[*] appName=pedroramos>"
      ],
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://192.168.15.7:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pedroramos</code></dd>\n            </dl>\n        </div>\n        "
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "sc = SparkContext(appName=\"pedroramos\")\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.sequenceFile(\"part-00000\")\n",
    "N_documentos = rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_COUNT_MIN = 10\n",
    "DOC_COUNT_MAX = N_documentos * 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpa_conteudo(conteudo):\n",
    "    to_remove = ['!', '.', ',', ':', '@', '#', '$', '%', '/', '\\\\', '|', '´', '`',\n",
    "                 '*', '&', '(', ')', '[', ']', '}', '{', '+', '-', '<', '>', '?', '°', '=', '\"', \n",
    "                 '_', \"'\", ';', '^', '~', '¨']\n",
    "    for i in to_remove:\n",
    "        conteudo = conteudo.replace(i, ' ')\n",
    "    return conteudo\n",
    "\n",
    "def conta_documento(item):\n",
    "    conteudo = limpa_conteudo(item[1])\n",
    "    palavras = conteudo.strip().split()\n",
    "    return [(i.lower(), 1) for i in set(palavras)]\n",
    "\n",
    "def calcula_idf(item):\n",
    "    palavra, contagem = item\n",
    "    idf = math.log10(N_documentos/contagem)\n",
    "    return (palavra, idf)\n",
    "\n",
    "def filtra_doc(item):\n",
    "    contagem = item[1]\n",
    "    return (contagem < DOC_COUNT_MAX) and (contagem > DOC_COUNT_MIN) \n",
    "\n",
    "rdd_idf = rdd \\\n",
    "    .flatMap(conta_documento) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .filter(filtra_doc) \\\n",
    "    .map(lambda x: (x[0], math.log10(N_documentos/x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conta_palavra(item):\n",
    "    conteudo = limpa_conteudo(item[1])\n",
    "    palavras = conteudo.strip().split()\n",
    "    return [(i.lower(), 1) for i in palavras]\n",
    "\n",
    "def calcula_freq(item):\n",
    "    palavra, contagem = item\n",
    "    freq = math.log10(1 + contagem)\n",
    "    return (palavra, freq)\n",
    "\n",
    "rdd_freq_fla = rdd \\\n",
    "    .filter(lambda x: \"flamengo\" in x[0]) \\\n",
    "    .flatMap(conta_palavra) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .map(calcula_freq)\n",
    "\n",
    "rdd_freq_flu = rdd \\\n",
    "    .filter(lambda x: \"fluminense\" in x[0]) \\\n",
    "    .flatMap(conta_palavra) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .map(calcula_freq)\n",
    "\n",
    "rdd_freq = rdd_freq_fla.intersection(rdd_freq_flu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_relevancia = rdd_freq.join(rdd_idf) \\\n",
    "    .map(lambda x: (x[0], x[1][0] * x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_relevancia = rdd_relevancia.takeOrdered(100, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_freq_flaOnly = rdd_freq_fla.subtractByKey(rdd_freq)\n",
    "rdd_freq_fluOnly = rdd_freq_flu.subtractByKey(rdd_freq)\n",
    "\n",
    "rdd_relevanciaFLA = rdd_freq_flaOnly.join(rdd_idf) \\\n",
    "    .map(lambda x: (x[0], x[1][0] * x[1][1]))\n",
    "top_relevanciaFLA = rdd_relevanciaFLA.takeOrdered(100, key=lambda x: -x[1])\n",
    "\n",
    "\n",
    "rdd_relevanciaFLU = rdd_freq_fluOnly.join(rdd_idf) \\\n",
    "    .map(lambda x: (x[0], x[1][0] * x[1][1]))\n",
    "top_relevanciaFLU = rdd_relevanciaFLU.takeOrdered(100, key=lambda x: -x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"top100_intersection.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for line in top_relevancia:\n",
    "        file.write(f\"{line[0]} : {line[1]}\\n\")\n",
    "\n",
    "with open(\"top100_FLA.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for line in top_relevanciaFLA:\n",
    "        file.write(f\"{line[0]} : {line[1]}\\n\")\n",
    "\n",
    "with open(\"top100_FLU.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for line in top_relevanciaFLU:\n",
    "        file.write(f\"{line[0]} : {line[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}