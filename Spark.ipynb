{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<SparkContext master=local[*] appName=pedroramos>"
      ],
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://LAPTOP-SUDG79B7.mshome.net:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pedroramos</code></dd>\n            </dl>\n        </div>\n        "
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "sc = SparkContext(appName=\"pedroramos\")\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.sequenceFile(\"part-00000\")\n",
    "N_documentos = rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_COUNT_MIN = 10\n",
    "DOC_COUNT_MAX = N_documentos * 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conta_documento(item):\n",
    "    conteudo = item[1]\n",
    "    palavras = conteudo.strip().split()\n",
    "    return [(i.lower(), 1) for i in set(palavras)]\n",
    "\n",
    "def calcula_idf(item):\n",
    "    palavra, contagem = item\n",
    "    idf = math.log10(N_documentos/contagem)\n",
    "    return (palavra, idf)\n",
    "\n",
    "def filtra_doc(item):\n",
    "    contagem = item[1]\n",
    "    return (contagem < DOC_COUNT_MAX) and (contagem > DOC_COUNT_MIN) \n",
    "\n",
    "rdd_idf = rdd \\\n",
    "    .flatMap(conta_documento) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .filter(filtra_doc) \\\n",
    "    .map(lambda x: (x[0], math.log10(N_documentos/x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conta_palavra(item):\n",
    "    conteudo = item[1]\n",
    "    palavras = conteudo.strip().split()\n",
    "    return [(i.lower(), 1) for i in palavras]\n",
    "\n",
    "def calcula_freq(item):\n",
    "    palavra, contagem = item\n",
    "    freq = math.log10(1 + contagem)\n",
    "    return (palavra, freq)\n",
    "\n",
    "rdd_freq_fla = rdd \\\n",
    "    .filter(lambda x: \"flamengo\" in x[0]) \\\n",
    "    .flatMap(conta_palavra) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .map(calcula_freq)\n",
    "\n",
    "rdd_freq_bot = rdd \\\n",
    "    .filter(lambda x: \"botafogo\" in x[0]) \\\n",
    "    .flatMap(conta_palavra) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .map(calcula_freq)\n",
    "\n",
    "rdd_freq = rdd_freq_fla.intersection(rdd_freq_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_relevancia = rdd_freq.join(rdd_idf) \\\n",
    "    .map(lambda x: (x[0], x[1][0] * x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_relevancia = rdd_relevancia.takeOrdered(100, key=lambda x: -x[1])\n",
    "with open(\"top100_intersection.txt\", \"w\") as file:\n",
    "    for line in top_relevancia:\n",
    "        file.write(f\"{line[0]} : {line[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_freq_flaOnly = rdd_freq_fla.subtractByKey(rdd_freq)\n",
    "rdd_freq_botOnly = rdd_freq_bot.subtractByKey(rdd_freq)\n",
    "\n",
    "rdd_relevanciaFLA = rdd_freq_flaOnly.join(rdd_idf) \\\n",
    "    .map(lambda x: (x[0], x[1][0] * x[1][1]))\n",
    "top_relevanciaFLA = rdd_relevanciaFLA.takeOrdered(100, key=lambda x: -x[1])\n",
    "with open(\"top100_FLA.txt\", \"w\") as file:\n",
    "    for line in top_relevancia:\n",
    "        file.write(f\"{line[0]} : {line[1]}\\n\")\n",
    "\n",
    "rdd_relevanciaBOT = rdd_freq_botOnly.join(rdd_idf) \\\n",
    "    .map(lambda x: (x[0], x[1][0] * x[1][1]))\n",
    "top_relevanciaBOT = rdd_relevanciaBOT.takeOrdered(100, key=lambda x: -x[1])\n",
    "with open(\"top100_BOT.txt\", \"w\") as file:\n",
    "    for line in top_relevancia:\n",
    "        file.write(f\"{line[0]} : {line[1]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}